{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7yHpux5ED8G"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "import cv2\n",
    "os.chdir(\"/content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_iuUjcwDPTsB"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GmmmZet3PeZ3"
   },
   "outputs": [],
   "source": [
    "!pip install luminoth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMpX-pHpvcGC"
   },
   "source": [
    "# Importing Training Weight from Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yt36zZUvlif"
   },
   "source": [
    "#### Kindly enter the same name and directory of checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ri62O3-wEPho"
   },
   "outputs": [],
   "source": [
    "!cp '/content/drive/My Drive/72209410e475.tar'  '72209410e475.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "7kgsdaHEuB3M",
    "outputId": "e3fe9e79-624a-412d-a8ed-a6524c14a930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Checkpoint 72209410e475 imported successfully.\n"
     ]
    }
   ],
   "source": [
    "!lumi checkpoint import 72209410e475.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3XD_JuKwLan"
   },
   "source": [
    "# Prediction From Simple Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPNss0gOwTro"
   },
   "source": [
    "#### Kindly upload some pdf page image For Table Detection. Like the sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3f7ut_jZuKe1",
    "outputId": "42487251-8940-47a5-ade9-1dc218eda23f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open image file\n",
    "os.chdir(\"/content\")\n",
    "img = cv2.imread('test_sample.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# perform transformations on image\n",
    "b = cv2.distanceTransform(img, distanceType=cv2.DIST_L2, maskSize=5)\n",
    "g = cv2.distanceTransform(img, distanceType=cv2.DIST_L1, maskSize=5)\n",
    "r = cv2.distanceTransform(img, distanceType=cv2.DIST_C, maskSize=5)\n",
    "# merge the transformed channels back to an image\n",
    "transformed_image = cv2.merge((b, g, r))\n",
    "cv2.imwrite('test_sample_preprocess.png', transformed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJAT6-6nyx14"
   },
   "source": [
    "**Enter the preprocessed image name and checkpoint name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8dyl8yYuydUX"
   },
   "outputs": [],
   "source": [
    "predictive=!lumi predict --checkpoint 72209410e475 test_sample_preprocess.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYRhGM9-EPeT"
   },
   "outputs": [],
   "source": [
    "predictive=eval(predictive[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "dP390DNB-8j_",
    "outputId": "36c7b7a9-c3f5-424a-9384-0ec0bd998d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tables found:  7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'bbox': [708, 1509, 2494, 2061], 'label': 'table', 'prob': 0.9486},\n",
       " {'bbox': [689, 307, 2546, 2104], 'label': 'table', 'prob': 0.9334},\n",
       " {'bbox': [1001, 910, 2485, 1747], 'label': 'table', 'prob': 0.844},\n",
       " {'bbox': [763, 316, 2504, 1193], 'label': 'table', 'prob': 0.8342},\n",
       " {'bbox': [798, 1604, 1484, 2035], 'label': 'table', 'prob': 0.801},\n",
       " {'bbox': [1610, 398, 2465, 2101], 'label': 'table', 'prob': 0.789},\n",
       " {'bbox': [661, 350, 2546, 685], 'label': 'table', 'prob': 0.6384}]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Total number of tables found: ',len(predictive['objects']))\n",
    "predictive['objects']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8E5HFKJ0NM4"
   },
   "source": [
    "**Drawing all the box on the image. you can set the range by change the for loop iterations.**\n",
    "\n",
    "Image is saved as 'sample_final_output.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7VfOB5_P_N_I",
    "outputId": "f0da5367-de0a-4935-9dc6-1f5216370ba3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('test_sample.png')\n",
    "for i in range(len(predictive['objects'])):\n",
    "  box_cor=predictive['objects'][i]['bbox']\n",
    "  cv2.rectangle(image, (box_cor[0],box_cor[1]),(box_cor[2],box_cor[3]), (255,0,0), 2)\n",
    "cv2.imwrite(\"sample_final_output.png\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwaxToVr_OC2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L2BDMSUC87Qw"
   },
   "source": [
    "# Prediction from Pdf File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1UBLoAkr9HCY"
   },
   "source": [
    "**Run the code pdf to images in local system then Upload the zip file of pdf pages images here.**\n",
    "\n",
    "This code is made for images for finding tables. In this case we need to first convert the pdf to images. There are multiple libraries exist for this purpose but Unfortunately all the libraries are depends on some kind of software like:\n",
    "\n",
    "\n",
    "\n",
    "*   ImageMagick\n",
    "*   pdftoppm (poppler)\n",
    "*   Ghostscript\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "These software are written in c++ so I don't think they can be run in colab.\n",
    "\n",
    "You can't avoid these software dependency. Even Imagemagick relies on Ghostscript for its PDF reading functions. The reason for this is the complexity of the PDF format: a PDF doesn't just contain bitmap information, but mostly vector shapes, transparencies etc. Furthermore it is quite complex to figure out which of these objects appear on which page.\n",
    "\n",
    "So the correct rendering of a PDF Page is clearly out of scope for a pure Python library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmkfDN5E9xrs"
   },
   "source": [
    "#### Run the Pdf_To_images.ipynb in local system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pH-eKje2FEBY"
   },
   "source": [
    "Upload the Pdf-Images.zip folder from the local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhyT4zvlAWs0"
   },
   "outputs": [],
   "source": [
    "!mkdir -p Pdf-Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "KRr2s64R-Jg-",
    "outputId": "de6c7fc3-15a6-4a02-9e9f-5183578cee8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Pdf-Images.zip\n",
      "  inflating: Pdf-Images/out_0.jpg    \n",
      "  inflating: Pdf-Images/out_1.jpg    \n",
      "  inflating: Pdf-Images/out_2.jpg    \n"
     ]
    }
   ],
   "source": [
    "!unzip \"Pdf-Images.zip\" -d Pdf-Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NODkE8Wl-mZ2"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "Images=glob.glob('Pdf-Images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LuRk60NW-kIa"
   },
   "outputs": [],
   "source": [
    "!mkdir -p Pdf-Images-Preprocess\n",
    "for image in Images:\n",
    "  # open image file\n",
    "  img = cv2.imread(image)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  # perform transformations on image\n",
    "  b = cv2.distanceTransform(img, distanceType=cv2.DIST_L2, maskSize=5)\n",
    "  g = cv2.distanceTransform(img, distanceType=cv2.DIST_L1, maskSize=5)\n",
    "  r = cv2.distanceTransform(img, distanceType=cv2.DIST_C, maskSize=5)\n",
    "  # merge the transformed channels back to an image\n",
    "  transformed_image = cv2.merge((b, g, r))\n",
    "  cv2.imwrite(image.replace('Pdf-Images','Pdf-Images-Preprocess'), transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKqmce3EBHtL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r8fkZ0_QHJaJ"
   },
   "source": [
    "**Enter the preprocessed image name and checkpoint name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOgSX7Q8HJap"
   },
   "source": [
    "**Predictions on all images.**\n",
    "\n",
    "Image is saved as 'sample_final_output.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ftJh5odvAWwP"
   },
   "outputs": [],
   "source": [
    "Images_preprocessed=glob.glob('Pdf-Images-Preprocess/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjmYPHuqHJaL"
   },
   "outputs": [],
   "source": [
    "from luminoth import Detector, read_image, vis_objects\n",
    "!mkdir -p Pdf_final_images\n",
    "detector = Detector(checkpoint='72209410e475')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1s5t5NEHJaQ"
   },
   "outputs": [],
   "source": [
    "for l in range(len(Images_preprocessed)):\n",
    "  image = read_image(Images_preprocessed[l])\n",
    "\n",
    "  # Returns a dictionary with the detections.\n",
    "  objects = detector.predict(image)\n",
    "  \n",
    "  image_save=read_image(Images[l])\n",
    "  \n",
    "  vis_objects(image_save, objects).save(Images_preprocessed[l].replace('Pdf-Images-Preprocess','Pdf_final_images'))\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCA0qdPDQXrx"
   },
   "source": [
    "# Saving the Images as PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "fKb9_Mi8HJaV",
    "outputId": "c680bd48-b060-4251-9f5f-e686c423fe35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fpdf\n",
      "  Downloading https://files.pythonhosted.org/packages/37/c6/608a9e6c172bf9124aa687ec8b9f0e8e5d697d59a5f4fad0e2d5ec2a7556/fpdf-1.7.2.tar.gz\n",
      "Building wheels for collected packages: fpdf\n",
      "  Building wheel for fpdf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9a/e9/77/4554ff5c99bc3f487c8d69620d8c41d99d54e9c54ab20ef4c9\n",
      "Successfully built fpdf\n",
      "Installing collected packages: fpdf\n",
      "Successfully installed fpdf-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hL0PISJDHJat"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z7se9w-S9p7T",
    "outputId": "0974f23a-25d1-4248-905a-bb4b77fe9656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Pdf_final_images/\" # get the path of images\n",
    "\n",
    "imagelist = listdir(path) # get list of all images\n",
    "\n",
    "pdf = FPDF('P','mm','A4') # create an A4-size pdf document \n",
    "\n",
    "x,y,w,h = 0,0,200,250\n",
    "\n",
    "for image in imagelist:\n",
    "\n",
    "    pdf.add_page()\n",
    "    pdf.image(path+image,x,y,w,h)\n",
    "\n",
    "pdf.output(\"pdf_with_table.pdf\",\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUgtoj459p-2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Table Detection Testing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
